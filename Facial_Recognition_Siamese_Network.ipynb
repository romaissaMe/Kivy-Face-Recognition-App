{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPFx6AIxtJdv",
        "outputId": "8a21a532-d661-4f28-875b-eff0fb69b511"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow tensorflow-gpu opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ARX4Ov8Fgd"
      },
      "source": [
        "# import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaDCYTAi8EfH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ4EL4Hu8rAF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Layer , MaxPooling2D, Input, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITHV83QLBEQM"
      },
      "source": [
        "# Set gpu growth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3CI3Xk_-QeK"
      },
      "outputs": [],
      "source": [
        "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu,True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5U7gpB-B0mo"
      },
      "source": [
        "# Structure Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKcyVFJ4Dmhd"
      },
      "outputs": [],
      "source": [
        "POS_PATH=os.path.join('data','positive')\n",
        "NEG_PATH=os.path.join('data','negative')\n",
        "ANC_PATH=os.path.join('data','anchor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clEpkUBmB0Z1"
      },
      "outputs": [],
      "source": [
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enZjeav-FdQg"
      },
      "source": [
        "# Collect Images (Positives and Anchors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbsRznc2Z1xI"
      },
      "source": [
        "## Untar labelled faces from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx_07FYRr74z"
      },
      "outputs": [],
      "source": [
        "!tar -xf lfw.tgz -C ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC_KoWfitGuv"
      },
      "outputs": [],
      "source": [
        "# Specify the directory pattern and filename pattern separately\n",
        "directory_pattern = 'lfw/*/'\n",
        "\n",
        "# Use glob to get a list of file paths that match the pattern\n",
        "file_list = glob.glob(f'{directory_pattern}*.jpg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkbWvHxCxu8u",
        "outputId": "e5000dc1-360c-40ee-c459-c60bc35d21f3"
      },
      "outputs": [],
      "source": [
        "print([os.path.basename(file) for file in file_list])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f94wqi0YxcEi"
      },
      "source": [
        "## collect negative images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uNlVLw3xghM"
      },
      "outputs": [],
      "source": [
        "for file in file_list:\n",
        "  old_path=file\n",
        "  new_path = os.path.join(NEG_PATH,os.path.basename(file))\n",
        "  os.replace(old_path,new_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXPJEDzqxuHG"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.rmtree('lfw')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M31Kyv58aGnL"
      },
      "source": [
        "## Collect Positives and Anchor Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "35OP40vIFjaL",
        "outputId": "080aeb8f-8098-45de-f5dc-d55f394c73c2"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "  print('error in opening camera')\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  frame=frame[20:300,200:550]\n",
        "  # Display the captured image \n",
        "  cv2.imshow('captured_image',frame)\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    break \n",
        "  if cv2.waitKey(1) & 0xFF == ord('a'):\n",
        "    imgname=os.path.join(ANC_PATH,f'{uuid.uuid1()}.jpg')\n",
        "    cv2.imwrite(imgname, frame)\n",
        "    \n",
        "  if cv2.waitKey(1) & 0xFF == ord('p'):\n",
        "    imgname=os.path.join(POS_PATH,f'{uuid.uuid1()}.jpg')\n",
        "    cv2.imwrite(imgname, frame)\n",
        "    \n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "# Release the camera\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l=glob.glob('data/anchor/*.jpg')\n",
        "len(l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igXmNNHa0vbZ"
      },
      "source": [
        "# Preprocess Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM3_-tnCBLnP"
      },
      "source": [
        "## get image directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "negative= tf.data.Dataset.list_files(f'{NEG_PATH}\\*.jpg').take(3000)\n",
        "positive= tf.data.Dataset.list_files(f'{POS_PATH}\\*.jpg').take(3000)\n",
        "anchor= tf.data.Dataset.list_files(f'{ANC_PATH}\\*.jpg').take(3000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neg_iterator=iter(negative)\n",
        "next(neg_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "negatives_list = negative.as_numpy_iterator()\n",
        "sample_img=negatives_list.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSlirvMABRWY"
      },
      "source": [
        "## Scale and resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(img_path):\n",
        "    img_bytes=tf.io.read_file(img_path)\n",
        "    img=tf.image.decode_image(img_bytes, channels=3)\n",
        "    img.set_shape([105, 105, 3])\n",
        "    img=tf.image.resize(img,(105,105),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    \n",
        "    img= tf.cast(img, tf.float32) / 255.0\n",
        "    # img= tf.image.convert_image_dtype(img, tf.float32)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = preprocess(sample_img)\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrt3pRsYCrwn"
      },
      "source": [
        "## Create labelled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives = tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data = positives.concatenate(negatives)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i=iter(data)\n",
        "i.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i=data.as_numpy_iterator()\n",
        "i.next()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaeZ0woqC-6j"
      },
      "source": [
        "## Build Train and Test Partition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_tuple(input_img,validation_img,label):\n",
        "    return(preprocess(input_img),preprocess(validation_img),label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=data.map(process_tuple)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i=data.as_numpy_iterator()\n",
        "sample=i.next()\n",
        "fig,ax=plt.subplots(1,2)\n",
        "ax[0].imshow(sample[0])\n",
        "ax[1].imshow(sample[1])\n",
        "plt.show()\n",
        "print(sample[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = data.take(round(len(data) * .7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = data.skip(round(len(data) * .7))\n",
        "test_data = test_data.take(round(len(test_data) * .3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## build embedding part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_embeding():\n",
        "    input = Input(shape=(105,105,3),name='input_image')\n",
        "\n",
        "    x = Conv2D(64,(10,10),activation='relu')(input)\n",
        "    x = MaxPooling2D(64,(2,2),padding='same')(x)\n",
        "\n",
        "    x = Conv2D(128,(7,7),activation='relu')(x)\n",
        "    x = MaxPooling2D(64,(2,2),padding='same')(x)\n",
        "\n",
        "    x = Conv2D(128,(4,4),activation='relu')(x)\n",
        "    x = MaxPooling2D(64,(2,2),padding='same')(x)\n",
        "\n",
        "    x = Conv2D(256,(4,4),activation='relu')(x)\n",
        "    x = Flatten() (x)\n",
        "    x = Dense(4096,activation='sigmoid')(x)\n",
        "    \n",
        "    return tf.keras.Model(inputs= [input], outputs= [x], name= 'embedding_blocks' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding = make_embeding()\n",
        "embedding.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build distance layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class L1Dist(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super().__init__()\n",
        "    \n",
        "    def call(self, input_embeddings, validation_embeddings):\n",
        "        return tf.math.abs(input_embeddings - validation_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "L1 = L1Dist()\n",
        "L1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Siamese Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def siames_model():\n",
        "    anchor_image = Input(shape= (105,105,3), name='input_image')\n",
        "    validation_image = Input(shape= (105,105,3), name='validation_image')\n",
        "\n",
        "    distance_layer = L1Dist()\n",
        "    distance_layer.__name = 'distance_layer'\n",
        "    distances = distance_layer(embedding(anchor_image),embedding(validation_image))\n",
        "\n",
        "    classifier = Dense(1, activation = 'sigmoid')(distances)\n",
        "    \n",
        "    return tf.keras.Model(inputs = [anchor_image,validation_image], outputs = [classifier], name = 'siamese_network')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "siamese_model = siames_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "binary_cross_loss = tf.losses.BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Establish Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Step function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "       X = batch[:2]\n",
        "       y = batch[2]\n",
        "\n",
        "       y_pred = siamese_model(X,training=True)\n",
        "       loss = binary_cross_loss(y,y_pred)\n",
        "\n",
        "       grad = tape.gradient(loss,siamese_model.trainable_variables)\n",
        "\n",
        "       opt.apply_gradients(zip(grad,siamese_model.trainable_variables))\n",
        "       \n",
        "       return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Trainning Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(data,epochs):\n",
        "   for epoch in range(epochs,epochs+1):\n",
        "      print(f'\\n EPOCH: {epoch}/{epochs}')\n",
        "      progbar = tf.keras.utils.Progbar(len(data))\n",
        "\n",
        "      for idx,batch in enumerate(data):\n",
        "         train_step(batch)\n",
        "         progbar.update(idx+1)\n",
        "\n",
        "      #save checkpoints\n",
        "      if epoch % 10 == 0:\n",
        "         checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS=50\n",
        "train(train_data,EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Recall, Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t=test_data.as_numpy_iterator()\n",
        "t.next()[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_input, test_validation, y_true =test_data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = siamese_model.predict([test_input,test_validation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p = Precision()\n",
        "p.update_state(y_true,y_pred)\n",
        "p.result().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = Recall()\n",
        "m.update_state(y_true,y_pred)\n",
        "m.result().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "siamese_model.save('siames_model.v0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reload model\n",
        "model=tf.keras.models.load_model('siames_model.v0',custom_objects={'L1Dist':L1Dist,'binary_cross_loss':tf.losses.BinaryCrossentropy})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Real Time Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verify(model, detection_threshold, verification_threshold):\n",
        "    results=[]\n",
        "    for image in os.listdir(os.path.join('application_data','verification_images')):\n",
        "        input_img = preprocess(os.path.join('application_data','input_image','input_image.jpg'))\n",
        "        validation_img = preprocess(os.path.join('application_data','input_image',image))\n",
        "        \n",
        "        #make predictions\n",
        "        pred = model.predict(list(np.expand_dims([input_img,validation_img],axis=1)))\n",
        "        results.append(pred)\n",
        "\n",
        "    detection = np.sum(np.array(results) > detection_threshold)\n",
        "    verification = detection / len(os.listdir(os.path.join('application_data','verification_images')))\n",
        "    verified = verification > verification_threshold\n",
        "\n",
        "    return results, verified\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    print('error while openning camera')\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    frame=frame[20:300,200:550,:]\n",
        "    # Display the captured image \n",
        "    cv2.imshow('captured_image',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break \n",
        "    if cv2.waitKey(2) & 0xFF == ord('c'):\n",
        "        path = os.path.join('application_data','input_image','input_image.jpg')\n",
        "        cv2.imwrite(path, frame)\n",
        "        results, verified = verify(model,0.5,0.5)  \n",
        "        print(verified)      \n",
        "        \n",
        "    \n",
        "cv2.destroyAllWindows()\n",
        "# Release the camera\n",
        "cap.release()\n",
        "\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
